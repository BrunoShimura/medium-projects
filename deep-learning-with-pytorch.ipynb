{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7770,  0.8291,  0.9105,  1.3073],\n",
       "        [-0.7678,  0.9684, -0.5793,  0.4304],\n",
       "        [-0.4778,  0.7128,  0.0751, -0.0655]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2d = torch.randn(3, 4)\n",
    "tensor_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d = torch.zeros(2, 3, 4)\n",
    "tensor_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch = torch.arange(10)\n",
    "my_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape and View\n",
    "my_torch = my_torch.reshape(2, 5)\n",
    "my_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape if we don't know the number of items using -1\n",
    "my_torch2 = torch.arange(10)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch.reshape(2, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch3 = torch.arange(10)\n",
    "my_torch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch3 = my_torch3.view(2, 5)\n",
    "my_torch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch4 = torch.arange(10)\n",
    "my_torch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch5 = my_torch4.reshape(2, 5)\n",
    "my_torch5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4141,    2,    3,    4,    5,    6,    7,    8,    9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch4[1] = 4141\n",
    "my_torch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 4141,    2,    3,    4],\n",
       "        [   5,    6,    7,    8,    9]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.tensor([1, 2, 3, 4])\n",
    "tensor_b = torch.tensor([5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "tensor_a + tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition Longhand\n",
    "torch.add(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction\n",
    "tensor_b - tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sub Function\n",
    "torch.sub(tensor_b, tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 12, 21, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "tensor_a * tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 12, 21, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mul longhand\n",
    "torch.mul(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0000, 3.0000, 2.3333, 2.0000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "tensor_b / tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0000, 3.0000, 2.3333, 2.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Div longhand\n",
    "torch.div(tensor_b, tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remainder modulos\n",
    "tensor_b % tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reaminder longhand\n",
    "torch.remainder(tensor_b, tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,    64,  2187, 65536])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponents / power\n",
    "torch.pow(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to write longhand\n",
    "tensor_a.add(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reassignment_\n",
    "tensor_a + tensor_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor_a = tensor_a + tensor_b\n",
    "tensor_a.add_(tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a basic neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model class that inherits nn.Module\n",
    "class Model(nn.Module):\n",
    "    # Input layer (4 features of the flower) -->\n",
    "    # Hidden Layer1( number of neurons) -->\n",
    "    # H2 (n) -->\n",
    "    # output (3 classes of iris flowers)\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__() # instantiate our nn.Module\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a manual seed for randomization\n",
    "torch.manual_seed(41)\n",
    "# Create an instance of model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
    "my_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2      0.0\n",
       "1             4.9          3.0           1.4          0.2      0.0\n",
       "2             4.7          3.2           1.3          0.2      0.0\n",
       "3             4.6          3.1           1.5          0.2      0.0\n",
       "4             5.0          3.6           1.4          0.2      0.0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3      2.0\n",
       "146           6.3          2.5           5.0          1.9      2.0\n",
       "147           6.5          3.0           5.2          2.0      2.0\n",
       "148           6.2          3.4           5.4          2.3      2.0\n",
       "149           5.9          3.0           5.1          1.8      2.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change last column from strings to integer\n",
    "my_df['species'] = my_df['species'].replace('setosa', 0.0)\n",
    "my_df['species'] = my_df['species'].replace('versicolor', 1.0)\n",
    "my_df['species'] = my_df['species'].replace('virginica', 2.0)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split! Set X, y\n",
    "X = my_df.drop('species', axis=1)\n",
    "y = my_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert these to numpy arrays\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y labels to tensors long\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the criterion of model to measure the error, how far off the predictions are from the data\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Choose Adam Optimizer, lr = learning rate (if error doesn't go down after a bunch of iterations(epochs), lower our learning rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.1251550912857056\n",
      "Epoch: 10 and loss: 1.0096259117126465\n",
      "Epoch: 20 and loss: 0.8157405853271484\n",
      "Epoch: 30 and loss: 0.585706353187561\n",
      "Epoch: 40 and loss: 0.3999636471271515\n",
      "Epoch: 50 and loss: 0.26768800616264343\n",
      "Epoch: 60 and loss: 0.17942364513874054\n",
      "Epoch: 70 and loss: 0.12151692062616348\n",
      "Epoch: 80 and loss: 0.0860118493437767\n",
      "Epoch: 90 and loss: 0.06520849466323853\n"
     ]
    }
   ],
   "source": [
    "# Train our model!\n",
    "# Epochs? (one run thru all the training data in our network)\n",
    "epochs = 100\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train) # Get prediction results\n",
    "\n",
    "    # Measure the loss/error, gonna be high at first\n",
    "    loss = criterion(y_pred, y_train) # predicted values vs teh y_train\n",
    "\n",
    "    # Keep Track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # print every 10 epoch\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "    # Do some back propagation: take the error rate of foward propagation and feed it back\n",
    "    # thru the network to fine tune the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph it out!\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
